{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbOCnJ2XlxMW"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ws0-wHLsvS6I",
    "outputId": "12317eae-3f27-4fcd-a6ee-12a550aad041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "Vu5wFnqnvr_B",
    "outputId": "324c933f-754f-4120-d294-70baf7025d71"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      2\u001b[0m files\u001b[38;5;241m.\u001b[39mupload()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0yzYnhRvfg1"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uga4Z6M2wmEb",
    "outputId": "bdca6880-d0df-4fc5-aeef-9a86cc607901"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S0qfcekwpuB"
   },
   "outputs": [],
   "source": [
    "!unzip breast-histopathology-images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w6JADEvwz4f"
   },
   "outputs": [],
   "source": [
    "mkdir /content/train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vw9G6G0hxzj9"
   },
   "outputs": [],
   "source": [
    "mkdir /content/train_data/benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdGYnVXmx5hr"
   },
   "outputs": [],
   "source": [
    "mkdir /content/train_data/malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2EAvhI220wO",
    "outputId": "cf19a8a4-7223-480f-9926-6c85f7d5caef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/17/1c/ccdd103cfcc9435a18819856fbbe0c20b8fa60bfc3343580de4be13f0668/scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sachin nimantha\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB 1.4 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.0/11.0 MB 667.8 kB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.1/11.0 MB 1.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/11.0 MB 1.5 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/11.0 MB 1.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.3/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/11.0 MB 2.0 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/11.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.7/11.0 MB 2.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/11.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.1/11.0 MB 2.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 2.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.0/11.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.2/11.0 MB 3.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.3/11.0 MB 3.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.5/11.0 MB 3.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.7/11.0 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.5/11.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/11.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.8/11.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.0 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.3/11.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.3/11.0 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.4/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.7/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.8/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.7/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.2/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.8/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikit-learn-1.5.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHMjctKtmAxn"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsssvxCs27qk",
    "outputId": "b09f7ca6-e2a5-4268-8d1f-4776c16e6174"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os,glob\n",
    "import cv2\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from math import exp, tanh\n",
    "from tokenize import Exponent\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from datetime import date\n",
    "from io import BytesIO\n",
    "from IPython import display\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import base64\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw4U0UXOmNXH"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuXfhCllocsl"
   },
   "outputs": [],
   "source": [
    "#create benign image dataset without duplicates\n",
    "\n",
    "# Get all png files from group of folders\n",
    "png_files = glob.glob(\"/content/**/0/*.png\", recursive=True)[:20000]\n",
    "\n",
    "# Move the png files to the dataset folder and filter duplicates\n",
    "for png_file in png_files:\n",
    "    if not os.path.exists(\"/content/train_data/benign/\" + os.path.basename(png_file)):\n",
    "        shutil.move(png_file, \"/content/train_data/benign/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpYc4lVTu2XK"
   },
   "outputs": [],
   "source": [
    "#create malignant image dataset without duplicates\n",
    "\n",
    "# Get all png files in group of folders\n",
    "png_files = glob.glob(\"/content/**/1/*.png\", recursive=True)[:20000]\n",
    "\n",
    "# Move the png files to the dataset folder\n",
    "for png_file in png_files:\n",
    "    if not os.path.exists(\"/content/train_data/malignant/\" + os.path.basename(png_file)):\n",
    "        shutil.move(png_file, \"/content/train_data/malignant/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3KncNpA5X69"
   },
   "outputs": [],
   "source": [
    "data_dir= \"/content/train_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a81mz6Qv7VUU"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 50\n",
    "img_width = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfVMDVbi6Q8O",
    "outputId": "32541e4e-f964-4cf4-96e4-5611f298e63b"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOYB1L877jVO",
    "outputId": "5794afa4-d400-48cd-8979-fe48a14238cf"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fhGRbPu8n-y",
    "outputId": "178f7846-6a19-4744-ce25-62645841965e"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "id": "xFhcWbZT84IY",
    "outputId": "88f479e9-933d-43df-ddc4-bcc9166190b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6GD8ytR9D7C",
    "outputId": "144f7a3c-5bd7-481c-d60f-648070b35382"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, labels_batch \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m      2\u001b[0m       \u001b[38;5;28mprint\u001b[39m(image_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m       \u001b[38;5;28mprint\u001b[39m(labels_batch\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "      print(image_batch.shape)\n",
    "      print(labels_batch.shape)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e0sv7m5G9FVk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m AUTOTUNE \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE\n\u001b[0;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mAUTOTUNE)\n\u001b[0;32m      4\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mAUTOTUNE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "66Q0OdQD9S39"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m normalization_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXDIgjDY-GFt",
    "outputId": "23bdfaba-6d4e-49ee-dba3-3a90ea74052d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m normalized_ds \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: (normalization_layer(x), y))\n\u001b[0;32m      2\u001b[0m image_batch, labels_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(normalized_ds))\n\u001b[0;32m      3\u001b[0m first_image \u001b[38;5;241m=\u001b[39m image_batch[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FAPLaLdZZ6eJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      2\u001b[0m   [\n\u001b[0;32m      3\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                       input_shape\u001b[38;5;241m=\u001b[39m(img_height,\n\u001b[0;32m      5\u001b[0m                                   img_width,\n\u001b[0;32m      6\u001b[0m                                   \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      7\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      8\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomZoom(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      9\u001b[0m   ]\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "is4i7_lmaA2m",
    "outputId": "8700268e-641b-440d-9a6e-0936f9c18455"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g3wlvHIsaE2G"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      4\u001b[0m   data_augmentation,\n\u001b[0;32m      5\u001b[0m   layers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m   layers\u001b[38;5;241m.\u001b[39mDense(num_classes)\n\u001b[0;32m     16\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dezjS0L3aJ4f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yu7sAbj4aPwz",
    "outputId": "af596f76-d64d-44c5-ba4b-4258cc1358db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzEO_OBHaTYC",
    "outputId": "070265b9-de60-44e1-8ca8-1c0ab5030162"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      3\u001b[0m   train_ds,\n\u001b[0;32m      4\u001b[0m   validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m      5\u001b[0m   epochs\u001b[38;5;241m=\u001b[39mepochs\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "tnTyhxLNjhgO",
    "outputId": "4bc51eae-bef0-4b48-9dd6-ab7e4e6effa4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "DpNb1bNIJtDe",
    "outputId": "9a09ccb6-082e-487a-ad09-2373d5214fb3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions on the validation dataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_ds)\n\u001b[0;32m      5\u001b[0m val_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract the true labels from the validation dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the validation dataset\n",
    "val_predictions = model.predict(val_ds)\n",
    "val_labels = []\n",
    "\n",
    "# Extract the true labels from the validation dataset\n",
    "for images, labels in val_ds:\n",
    "    val_labels.extend(labels.numpy())\n",
    "\n",
    "# Convert predictions to class labels (0 or 1)\n",
    "val_pred_labels = np.argmax(val_predictions, axis=-1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, val_pred_labels)\n",
    "precision = precision_score(val_labels, val_pred_labels)\n",
    "recall = recall_score(val_labels, val_pred_labels)\n",
    "f1 = f1_score(val_labels, val_pred_labels)\n",
    "confusion = confusion_matrix(val_labels, val_pred_labels)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion, annot=True, linewidths=0.01, cmap=\"BuPu\", linecolor=\"gray\", fmt='.1f')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qOAjlXKFs9vT"
   },
   "outputs": [],
   "source": [
    "DATADIR = \"/content/10254/1/10254_idx5_x1601_y1301_class1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_rzBdhltB-u",
    "outputId": "87c1c746-3e37-4a44-80a0-73514629bf0d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_img(\n\u001b[0;32m      2\u001b[0m     DATADIR, target_size\u001b[38;5;241m=\u001b[39m(img_height, img_width)\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[0;32m      5\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Create a batch\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    DATADIR, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
